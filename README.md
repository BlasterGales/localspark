# ü¶ô Ollama Spark - Asistente de Desarrollo IA Local

Un clon de GitHub Spark que utiliza Ollama para ejecutar modelos de IA localmente, proporcionando una experiencia de desarrollo sin depender de servicios en la nube.

## üìã Requisitos Previos

Antes de comenzar, aseg√∫rate de tener instalado:

- **Node.js** (versi√≥n 18 o superior)
- **npm** o **yarn** como gestor de paquetes
- **Ollama** instalado y ejecut√°ndose localmente

## üõ†Ô∏è Instalaci√≥n de Ollama

### Para macOS:
```bash
curl -fsSL https://ollama.ai/install.sh | sh
```

### Para Linux:
```bash
curl -fsSL https://ollama.ai/install.sh | sh
```

### Para Windows:
1. Descarga el instalador desde [ollama.ai](https://ollama.ai)
2. Ejecuta el archivo descargado y sigue las instrucciones

### Verificar instalaci√≥n de Ollama:
```bash
ollama --version
```

## üöÄ Instalaci√≥n del Proyecto

### 1. Clonar el repositorio
```bash
git clone [URL_DEL_REPOSITORIO]
cd ollama-spark
```

### 2. Instalar dependencias
```bash
npm install
```

### 3. Iniciar Ollama (si no est√° ejecut√°ndose)
```bash
ollama serve
```

### 4. Descargar modelos de IA
Descarga al menos un modelo para usar con la aplicaci√≥n:

```bash
# Modelos recomendados (elige uno o varios):

# Modelo ligero y r√°pido
ollama pull llama3.2:3b

# Modelo equilibrado
ollama pull llama3.2:7b

# Modelo m√°s potente (requiere m√°s RAM)
ollama pull llama3.2:13b

# Modelo especializado en c√≥digo
ollama pull codellama:7b

# Modelo general vers√°til
ollama pull mistral:7b
```

### 5. Verificar que los modelos est√©n disponibles
```bash
ollama list
```

## üéØ Ejecutar la Aplicaci√≥n

### Modo de desarrollo:
```bash
npm run dev
```

La aplicaci√≥n estar√° disponible en: `http://localhost:5173`

### Construir para producci√≥n:
```bash
npm run build
```

### Vista previa de la construcci√≥n:
```bash
npm run preview
```

## üìñ C√≥mo Usar

1. **Conexi√≥n autom√°tica**: La aplicaci√≥n se conectar√° autom√°ticamente a Ollama (localhost:11434)

2. **Seleccionar modelo**: En la parte superior, selecciona uno de los modelos que descargaste

3. **Subir archivos de proyecto** (opcional):
   - Usa la barra lateral izquierda para subir archivos de tu proyecto
   - Esto proporciona contexto al modelo sobre tu c√≥digo

4. **Iniciar conversaci√≥n**:
   - Escribe tu pregunta o solicitud en el campo de texto inferior
   - El modelo responder√° bas√°ndose en tu consulta y el contexto de los archivos

## üîß Caracter√≠sticas

- **Chat en tiempo real** con modelos de Ollama
- **Carga de archivos de proyecto** para proporcionar contexto
- **Interfaz similar a GitHub Spark** pero completamente local
- **M√∫ltiples modelos** disponibles seg√∫n tus necesidades
- **Historial de conversaciones** persistente
- **Sintaxis highlighting** para c√≥digo
- **Tema oscuro** optimizado para desarrolladores

## üõ†Ô∏è Comandos Disponibles

```bash
# Desarrollo
npm run dev          # Inicia el servidor de desarrollo
npm run build        # Construye la aplicaci√≥n para producci√≥n
npm run preview      # Vista previa de la construcci√≥n
npm run lint         # Ejecuta el linter
npm run optimize     # Optimiza dependencias

# Ollama
ollama serve         # Inicia el servidor de Ollama
ollama list          # Lista modelos instalados
ollama pull [modelo] # Descarga un nuevo modelo
ollama rm [modelo]   # Elimina un modelo
```

## üîç Soluci√≥n de Problemas

### Error: "No se puede conectar a Ollama"
- Verifica que Ollama est√© ejecut√°ndose: `ollama serve`
- Confirma que est√© en el puerto correcto (11434): `curl http://localhost:11434/api/tags`

### Error: "No hay modelos disponibles"
- Descarga al menos un modelo: `ollama pull llama3.2:3b`
- Verifica que se instal√≥: `ollama list`

### Problemas de rendimiento
- Usa modelos m√°s peque√±os (3b en lugar de 13b)
- Aseg√∫rate de tener suficiente RAM libre
- Cierra otras aplicaciones que consuman mucha memoria

### Puerto ocupado
- Mata procesos en el puerto 5000: `npm run kill`
- O usa un puerto diferente: `npm run dev -- --port 3000`

## üìä Requisitos del Sistema

### M√≠nimos:
- **RAM**: 8GB (para modelos 3b)
- **Espacio**: 10GB libres
- **CPU**: Procesador moderno de 64 bits

### Recomendados:
- **RAM**: 16GB+ (para modelos 7b-13b)
- **Espacio**: 50GB+ (para m√∫ltiples modelos)
- **CPU**: 8+ n√∫cleos
- **GPU**: Compatible con CUDA (opcional, mejora rendimiento)

## ü§ù Contribuciones

Las contribuciones son bienvenidas. Por favor:

1. Haz fork del repositorio
2. Crea una rama para tu feature (`git checkout -b feature/nueva-caracteristica`)
3. Commit tus cambios (`git commit -am 'A√±ade nueva caracter√≠stica'`)
4. Push a la rama (`git push origin feature/nueva-caracteristica`)
5. Abre un Pull Request

## üìÑ Licencia

Este proyecto est√° licenciado bajo los t√©rminos de la licencia MIT. Los recursos del Spark Template de GitHub est√°n bajo Copyright GitHub, Inc.